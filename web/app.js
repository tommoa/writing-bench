var S=(K,Q=document)=>Q.querySelector(K),h=(K,Q=document)=>[...Q.querySelectorAll(K)];function q(K,Q={},...W){let X=document.createElement(K);for(let[U,N]of Object.entries(Q)){if(N==null)continue;if(U==="className"&&typeof N==="string")X.className=N;else if(U.startsWith("on")&&typeof N==="function")X.addEventListener(U.slice(2).toLowerCase(),N);else if(U==="innerHTML"&&typeof N==="string")X.innerHTML=N;else if(typeof N==="string")X.setAttribute(U,N)}for(let U of W)if(typeof U==="string")X.appendChild(document.createTextNode(U));else if(U)X.appendChild(U);return X}var i={index:null},m=null;function qq(){let K=new URLSearchParams(location.search),Q=K.get("run");if(Q)return{page:"run",id:Q};if(K.get("page")==="runs")return{page:"runs"};if(K.get("page")==="methodology")return{page:"methodology"};return{page:"dashboard"}}async function Yq(){let K=await fetch("data/runs.json");if(!K.ok)throw Error("No data found. Run a benchmark and export first.");return K.json()}async function Zq(K){let Q=await fetch(`data/runs/${K}.json`);if(!Q.ok)throw Error(`Run ${K} not found`);return Q.json()}function b(K){let Q=S("#app");if(Q.innerHTML="",typeof K==="string")Q.innerHTML=K;else Q.appendChild(K)}function Kq(K){b(`<div id="error">${K}</div>`)}function Qq(K){return new Date(K).toLocaleDateString("en-US",{year:"numeric",month:"short",day:"numeric",hour:"2-digit",minute:"2-digit"})}function _q(K){if(K>=100)return`${Math.round(K)}`;if(K>=10)return K.toFixed(1);return K.toFixed(2)}function t(K){let Q=K.usage.inputTokens+K.usage.outputTokens;if(K.fromCache)return q("p",{className:"muted small mt-1"},`${Q} tokens | [cached]`);let W=K.usage.cacheReadTokens?` (${K.usage.cacheReadTokens} cached)`:"",X=K.cost.totalUncached!=null&&K.cost.totalUncached>K.cost.total+0.00005?` (uncached: $${K.cost.totalUncached.toFixed(4)})`:"";return q("p",{className:"muted small mt-1"},`${Q} tokens${W} | $${K.cost.total.toFixed(4)}${X} | ${(K.latencyMs/1000).toFixed(1)}s`)}function Nq(K){let Q=K.usage?K.usage.inputTokens+K.usage.outputTokens:0;if(K.fromCache)return q("p",{className:"muted small mt-1"},`${Q} tokens | [cached]`);let W=K.cost?K.cost.total:0,X=K.latencyMs?(K.latencyMs/1000).toFixed(1):"?";return q("p",{className:"muted small mt-1"},`${Q} tokens | $${W.toFixed(4)} | ${X}s`)}function Hq(K){let Q=document.createDocumentFragment();if(K.cumulativeElo.writing.length>0)Q.appendChild(q("h2",{},"Writer ELO")),Q.appendChild(p(K.cumulativeElo.writing,["initial","revised"]));if(K.cumulativeElo.feedback.length>0)Q.appendChild(q("h2",{},"Feedback Provider ELO")),Q.appendChild(p(K.cumulativeElo.feedback,["feedback"]));if(K.cumulativeElo.byTag&&Object.keys(K.cumulativeElo.byTag).length>0){Q.appendChild(q("h2",{},"ELO by Tag"));for(let[W,X]of Object.entries(K.cumulativeElo.byTag)){let U=q("details");U.appendChild(q("summary",{},W)),U.appendChild(q("div",{className:"details-content"},p(X,["initial","revised"]))),Q.appendChild(U)}}if(K.eloHistory.length>1)Q.appendChild(q("h2",{},"ELO History")),Q.appendChild(Gq(K.eloHistory));if(K.runs.length>0)Q.appendChild(q("h2",{},"Recent Runs")),Q.appendChild(Uq(K.runs));if(K.runs.length===0&&K.cumulativeElo.writing.length===0)Q.appendChild(q("p",{className:"muted mt-2"},"No benchmark data yet. Run a benchmark and export results."));b(Q)}function p(K,Q){let W=q("table"),X={initial:"Write",initialJudging:"Judge",feedback:"Feedback",revised:"Revise",revisedJudging:"Re-Judge"},U=(Q??[]).filter((Y)=>K.some((V)=>(V.costByStage?.[Y]??0)>0)).map((Y)=>({key:Y,label:X[Y]??Y})),N=U.length>0&&K.some((Y)=>U.some((V)=>(Y.costByStage?.[V.key]??0)>0)),G=U.length>0&&K.some((Y)=>U.some((V)=>(Y.tokensByStage?.[V.key]??0)>0)),J=[q("th",{className:"rank"},"#"),q("th",{},"Model"),q("th",{className:"sortable"},"ELO"),q("th",{},"Matches")];if(N)for(let Y of U)J.push(q("th",{className:"cost"},Y.label));if(G)for(let Y of U)J.push(q("th",{},`${Y.label} Tokens`));W.appendChild(q("thead",{},q("tr",{},...J)));let D=q("tbody");return K.forEach((Y,V)=>{let H=V===0?"rating top":V===K.length-1?"rating bottom":"rating",F=[q("td",{className:"rank"},String(V+1)),q("td",{},Y.model),q("td",{className:H},String(Y.rating)),q("td",{className:"muted"},String(Y.matchCount))];if(N)for(let z of U){let _=Y.costByStage?.[z.key]??0;F.push(q("td",{className:"cost"},_>0?`$${_.toFixed(4)}`:"-"))}if(G)for(let z of U){let _=Y.tokensByStage?.[z.key]??0;F.push(q("td",{className:"muted"},_>0?_.toLocaleString():"-"))}D.appendChild(q("tr",{},...F))}),W.appendChild(D),W}function Gq(K){let Q=q("div"),W=new Set;K.forEach((X)=>Object.keys(X.ratings).forEach((U)=>W.add(U)));for(let X of W){let U=K.map((z)=>z.ratings[X]).filter((z)=>z!=null);if(U.length<2)continue;let N=Math.min(...U),J=Math.max(...U)-N||1,D=120,Y=30,V=2,H=U.map((z,_)=>{let w=V+_/(U.length-1)*(D-2*V),R=V+(1-(z-N)/J)*(Y-2*V);return`${w},${R}`}),F=`<svg viewBox="0 0 ${D} ${Y}"><path d="M${H.join("L")}"/></svg>`;Q.appendChild(q("div",{className:"mb-1"},q("span",{},X+" "),q("span",{className:"sparkline",innerHTML:F}),q("span",{className:"muted small"},` ${U[U.length-1]}`)))}return Q}function Uq(K){let Q=q("ul",{className:"run-list"});for(let W of K){let X=q("a",{href:`?run=${W.id}`},Qq(W.timestamp)),U=q("span",{className:"run-meta"},`${W.models.join(", ")} | ${W.promptCount} prompts | $${(W.totalCostUncached??W.totalCost).toFixed(4)}`);Q.appendChild(q("li",{},X,U))}return Q}function Fq(K){let Q=document.createDocumentFragment();if(Q.appendChild(q("h2",{},"All Runs")),K.runs.length>0)Q.appendChild(Uq(K.runs));else Q.appendChild(q("p",{className:"muted mt-2"},"No runs yet. Run a benchmark and export results."));b(Q)}function Oq(K){let Q=document.createDocumentFragment();Q.appendChild(q("p",{},q("a",{href:"?"},"< back to leaderboard")));let W=K.meta.totalCostUncached??K.meta.totalCost;Q.appendChild(q("h2",{},`Run: ${Qq(K.config.timestamp)} — $${W.toFixed(2)}`));let X=K.config.models.map((Y)=>Y.label).join(", ");if(K.config.judges&&K.config.judges.length>0){let Y=K.config.judges.map((V)=>V.label).join(", ");Q.appendChild(q("p",{className:"muted"},`Writers: ${X} | Judges: ${Y}`))}else Q.appendChild(q("p",{className:"muted"},`Models: ${X}`));let U={costByModelByStage:K.meta.costByModelByStageUncached??{},tokensByModelByStage:K.meta.tokensByModelByStage??{},speedByModel:K.meta.speedByModel};if(Q.appendChild(q("h2",{},"Initial Writer ELO")),Q.appendChild(u(K.elo.initial.ratings,{...U,costStages:["initial"]})),Q.appendChild(q("h2",{},"Revised Writer ELO")),Q.appendChild(u(K.elo.revised.ratings,{...U,costStages:["revised"]})),K.elo.revised.feedbackRatings&&K.elo.revised.feedbackRatings.length>0)Q.appendChild(q("h2",{},"Feedback Provider ELO")),Q.appendChild(u(K.elo.revised.feedbackRatings,{...U,costStages:["feedback"]}));if(K.elo.initial.byTag&&Object.keys(K.elo.initial.byTag).length>0){Q.appendChild(q("h2",{},"ELO by Tag"));for(let[Y,V]of Object.entries(K.elo.initial.byTag)){let H=q("details");H.appendChild(q("summary",{},Y));let F=q("div",{className:"details-content"});if(F.appendChild(q("h4",{},"Initial")),F.appendChild(u(V,{...U,costStages:["initial"]})),K.elo.revised.byTag?.[Y])F.appendChild(q("h4",{},"Revised")),F.appendChild(u(K.elo.revised.byTag[Y],{...U,costStages:["revised"]}));H.appendChild(F),Q.appendChild(H)}}let N=q("div",{className:"section-header"});N.appendChild(q("h2",{},"Outputs by Prompt"));let G=document.createElement("select");G.className="prompt-filter-select",G.appendChild(new Option("All prompts","all"));let J=[...new Set(K.config.prompts.flatMap((Y)=>Y.tags))].sort();if(J.length>1)for(let Y of J)G.appendChild(new Option(`Tag: ${Y}`,`tag:${Y}`));for(let Y of K.config.prompts)G.appendChild(new Option(Y.name,`id:${Y.id}`));N.appendChild(G),Q.appendChild(N);let D=q("div",{id:"prompt-sections"});for(let Y of K.config.prompts){let V=Jq(K,Y);V.setAttribute("data-prompt-id",Y.id),V.setAttribute("data-prompt-tags",Y.tags.join(",")),D.appendChild(V)}Q.appendChild(D),G.addEventListener("change",()=>{let Y=G.value;for(let V of h("[data-prompt-id]",D))if(Y==="all")V.style.display="";else if(Y.startsWith("tag:")){let H=Y.slice(4),F=(V.getAttribute("data-prompt-tags")??"").split(",");V.style.display=F.includes(H)?"":"none"}else if(Y.startsWith("id:")){let H=Y.slice(3);V.style.display=V.getAttribute("data-prompt-id")===H?"":"none"}}),Q.appendChild(q("h2",{},"Judgments")),Q.appendChild(zq(K)),Q.appendChild(q("h2",{},"Run Metadata")),Q.appendChild(Dq(K)),b(Q)}function o(K,Q){return q("div",{className:"cost-item"},q("div",{className:"label"},K),q("div",{className:"value"},Q))}function u(K,Q){let W=q("table"),X={initial:"Write",initialJudging:"Judge",feedback:"Feedback",revised:"Revise",revisedJudging:"Re-Judge"},U=Q?.costByModelByStage??{},N=Q?.tokensByModelByStage??{},G=K.map((_)=>_.model),J=(Q?.costStages??[]).filter((_)=>G.some((w)=>(U[w]?.[_]??0)>0||(N[w]?.[_]??0)>0)).map((_)=>({key:_,label:X[_]??_})),D=J.length>0&&G.some((_)=>J.some((w)=>(U[_]?.[w.key]??0)>0)),Y=J.length>0&&G.some((_)=>J.some((w)=>(N[_]?.[w.key]??0)>0)),V=Q?.speedByModel!=null&&Object.keys(Q.speedByModel).length>0,H=K.some((_)=>_.ci95!=null),F=[q("th",{className:"rank"},"#"),q("th",{},"Model"),q("th",{},"ELO")];if(H)F.push(q("th",{className:"ci"},"±CI"));if(F.push(q("th",{},"W/L/T")),D)for(let _ of J)F.push(q("th",{className:"cost"},_.label));if(Y)for(let _ of J)F.push(q("th",{},`${_.label} Tokens`));if(V)F.push(q("th",{},"Speed"));W.appendChild(q("thead",{},q("tr",{},...F)));let z=q("tbody");return K.forEach((_,w)=>{let R=w===0?"rating top":w===K.length-1?"rating bottom":"rating",$=`${_.wins}/${_.losses}/${_.ties}`,y=[q("td",{className:"rank"},String(w+1)),q("td",{},_.model),q("td",{className:R},String(_.rating))];if(H)y.push(q("td",{className:"ci"},_.ci95!=null?`±${_.ci95}`:"-"));if(y.push(q("td",{className:"wlt"},$)),D){let I=U[_.model]??{};for(let L of J){let E=I[L.key]??0;y.push(q("td",{className:"cost"},E>0?`$${E.toFixed(4)}`:"-"))}}if(Y){let I=N[_.model]??{};for(let L of J){let E=I[L.key]??0;y.push(q("td",{className:"muted"},E>0?E.toLocaleString():"-"))}}if(V){let I=Q.speedByModel[_.model],L=I?`${_q(I.tokensPerSecond)} tok/s`:"-";y.push(q("td",{className:"speed"},L))}z.appendChild(q("tr",{},...y))}),W.appendChild(z),W}function Jq(K,Q){let W=q("details");W.appendChild(q("summary",{},`${Q.name} (${Q.tags.join(", ")})`));let X=q("div",{className:"details-content"});X.appendChild(q("p",{className:"muted small"},Q.description));let U=K.samples.filter((V)=>V.promptId===Q.id&&V.stage==="initial").sort((V,H)=>V.model.localeCompare(H.model)||V.outputIndex-H.outputIndex);if(U.length===0)return X.appendChild(q("p",{className:"muted"},"No outputs.")),W.appendChild(X),W;let N=U.length>4,G=q("div"),J=U.map((V)=>{let F=U.filter((z)=>z.model===V.model).length>1?` #${V.outputIndex+1}`:"";return`${V.model}${F}`});function D(V){h(".tab-content",G).forEach((F)=>F.classList.remove("active"));let H=`prompt-${Q.id}-${V}`;S(`#${H}`,G)?.classList.add("active")}let Y;if(N){let V=document.createElement("select");V.className="model-select";for(let H=0;H<J.length;H++)V.appendChild(new Option(J[H],String(H)));V.addEventListener("change",()=>{D(Number(V.value))}),Y=q("div",{className:"tabs tabs-dropdown"}),Y.appendChild(V)}else{Y=q("div",{className:"tabs"});for(let V=0;V<J.length;V++){let H=q("button",{className:V===0?"tab active":"tab",onClick:()=>{h(".tab",Y).forEach((F)=>F.classList.remove("active")),H.classList.add("active"),D(V)}},J[V]);Y.appendChild(H)}}return U.forEach((V,H)=>{let F=`prompt-${Q.id}-${H}`,z=q("div",{id:F,"data-sample-id":V.id,className:H===0?"tab-content active":"tab-content"});z.appendChild(q("div",{className:"output-text"},V.text)),z.appendChild(t(V));let _=K.judgments.filter((R)=>R.sampleA===V.id||R.sampleB===V.id).length;if(_>0)z.appendChild(q("button",{className:"view-judgments-btn",onClick:()=>m?.focusSample(V.id)},`view ${_} judgments →`));let w=K.feedback.filter((R)=>R.targetSampleId===V.id).sort((R,$)=>R.sourceModel.localeCompare($.sourceModel));for(let R of w){let $=q("details");$.appendChild(q("summary",{},`Feedback from ${R.sourceModel}`));let y=q("div",{className:"details-content"}),I=q("div",{className:"feedback-text"});I.appendChild(document.createTextNode(R.text)),I.appendChild(Nq(R)),y.appendChild(I);let L=K.samples.find((E)=>E.stage==="revised"&&E.feedbackUsed===R.id&&E.promptId===Q.id);if(L){let E=q("div",{className:"revision-nested",id:`sample-${L.id}`});E.appendChild(q("div",{className:"muted small"},`${L.model}'s revision:`)),E.appendChild(q("div",{className:"output-text"},L.text)),E.appendChild(t(L));let A=K.judgments.filter((x)=>x.sampleA===L.id||x.sampleB===L.id).length;if(A>0)E.appendChild(q("button",{className:"view-judgments-btn",onClick:()=>m?.focusSample(L.id)},`view ${A} judgments →`));y.appendChild(E)}$.appendChild(y),z.appendChild($)}G.appendChild(z)}),X.appendChild(Y),X.appendChild(G),W.appendChild(X),W}function r(K){let Q=K.parentElement;while(Q){if(Q.tagName==="DETAILS")Q.setAttribute("open","");Q=Q.parentElement}}function l(K,Q){let W=Q.samples.find((N)=>N.id===K);if(!W)return;let X=Q.samples.filter((N)=>N.promptId===W.promptId&&N.stage==="initial").sort((N,G)=>N.model.localeCompare(G.model)||N.outputIndex-G.outputIndex),U=null;if(W.stage==="initial"){let N=X.findIndex((D)=>D.id===K);if(N===-1)return;let G=`prompt-${W.promptId}-${N}`,J=S(`#${G}`);if(!J)return;r(J),e(J,N),U=J}else{let N=S(`#sample-${K}`);if(!N)return;if(r(N),W.originalSampleId){let G=X.findIndex((J)=>J.id===W.originalSampleId);if(G!==-1){let J=`prompt-${W.promptId}-${G}`,D=S(`#${J}`);if(D)e(D,G)}}U=N}if(U)U.scrollIntoView({behavior:"smooth",block:"start"}),U.classList.add("scroll-highlight"),U.addEventListener("animationend",()=>U.classList.remove("scroll-highlight"),{once:!0})}function e(K,Q){let W=K.parentElement;if(!W)return;let X=W.previousElementSibling;if(X&&X.classList.contains("tabs")){let U=S("select.model-select",X);if(U)U.value=String(Q);h(".tab",X).forEach((N,G)=>{N.classList.toggle("active",G===Q)})}h(".tab-content",W).forEach((U)=>U.classList.remove("active")),K.classList.add("active")}function Rq(K,Q){let W=Q.get(K.sampleA),X=Q.get(K.sampleB);if(K.stage==="improvement"){let U=W?.stage==="initial",N=U?W:X,G=U?X:W,J=G?.feedbackModel??"?",D=`${N?.model??"?"} (original)`,Y=`${G?.model??"?"} (revised, fb: ${J})`,V;if(K.winner==="tie")V="Tie";else V=(K.winner==="A"?W:X)?.stage==="initial"?"original":"revised";return U?{labelA:D,labelB:Y,winnerLabel:V}:{labelA:Y,labelB:D,winnerLabel:V}}if(K.stage==="revised"){let U=W?.feedbackModel?` (fb: ${W.feedbackModel})`:"",N=X?.feedbackModel?` (fb: ${X.feedbackModel})`:"";return{labelA:`${W?.model??"?"}${U}`,labelB:`${X?.model??"?"}${N}`,winnerLabel:K.winner==="tie"?"Tie":K.winner==="A"?W?.model??"?":X?.model??"?"}}return{labelA:W?.model??"?",labelB:X?.model??"?",winnerLabel:K.winner==="tie"?"Tie":K.winner==="A"?W?.model??"?":X?.model??"?"}}function zq(K){let Q=q("div");Q.id="judgments-section";let W=K.judgments;if(W.length===0)return Q.appendChild(q("p",{className:"muted"},"No judgments.")),Q;let X=new Map(K.samples.map((Z)=>[Z.id,Z])),U=[...new Set(W.map((Z)=>Z.stage))].sort(),N=[...new Set(W.map((Z)=>Z.judgeModel))].sort(),G=[...new Set(K.samples.map((Z)=>Z.model))].sort(),J=K.config.prompts,D=[...new Set(J.flatMap((Z)=>Z.tags))].sort(),Y="all",V="all",H="all",F="all",z="all",_=null,w=25,R=0,$=q("div",{className:"judgment-filters"}),y=document.createElement("select");if(y.appendChild(new Option("All prompts","all")),D.length>1)for(let Z of D)y.appendChild(new Option(`Tag: ${Z}`,`tag:${Z}`));for(let Z of J)y.appendChild(new Option(Z.name,`id:${Z.id}`));let I=document.createElement("select");I.appendChild(new Option("All stages","all"));for(let Z of U)I.appendChild(new Option(Z,Z));let L=document.createElement("select");L.appendChild(new Option("All judges","all"));for(let Z of N)L.appendChild(new Option(Z,Z));let E=document.createElement("select");E.appendChild(new Option("All models","all"));for(let Z of G)E.appendChild(new Option(Z,Z));let A=document.createElement("select");A.appendChild(new Option("All models","all"));for(let Z of G)A.appendChild(new Option(Z,Z));$.appendChild(q("span",{className:"muted small"},"Prompt: ")),$.appendChild(y),$.appendChild(q("span",{className:"muted small"}," Stage: ")),$.appendChild(I),$.appendChild(q("span",{className:"muted small"}," Judge: ")),$.appendChild(L),$.appendChild(q("span",{className:"muted small"}," Model A: ")),$.appendChild(E),$.appendChild(q("span",{className:"muted small"}," vs B: ")),$.appendChild(A),Q.appendChild($);let x=q("div",{className:"sample-filter-badge"});x.style.display="none",Q.appendChild(x);let B=q("div",{className:"h2h-summary"});B.style.display="none",Q.appendChild(B);let v=q("div");Q.appendChild(v);let P=()=>{let Z=W;if(_){Z=Z.filter((T)=>T.sampleA===_||T.sampleB===_);let O=X.get(_);x.innerHTML="",x.style.display="flex",x.appendChild(q("span",{},`Showing judgments for ${O?.model??"unknown"}'s output`)),x.appendChild(q("button",{className:"badge-clear",onClick:()=>{_=null,P()}},"✕ clear"))}else x.style.display="none";if(z!=="all"){if(z.startsWith("tag:")){let O=z.slice(4),T=new Set(J.filter((C)=>C.tags.includes(O)).map((C)=>C.id));Z=Z.filter((C)=>T.has(C.promptId))}else if(z.startsWith("id:")){let O=z.slice(3);Z=Z.filter((T)=>T.promptId===O)}}if(Y!=="all")Z=Z.filter((O)=>O.stage===Y);if(V!=="all")Z=Z.filter((O)=>O.judgeModel===V);if(H!=="all"&&F!=="all")Z=Z.filter((O)=>{let T=X.get(O.sampleA)?.model,C=X.get(O.sampleB)?.model;return T===H&&C===F||T===F&&C===H});else if(H!=="all")Z=Z.filter((O)=>{let T=X.get(O.sampleA)?.model,C=X.get(O.sampleB)?.model;return T===H||C===H});else if(F!=="all")Z=Z.filter((O)=>{let T=X.get(O.sampleA)?.model,C=X.get(O.sampleB)?.model;return T===F||C===F});if(H!=="all"&&F!=="all"&&H!==F){let O=0,T=0,C=0;for(let k of Z){let M=X.get(k.sampleA)?.model;if(k.winner==="tie")C++;else if(k.winner==="A")if(M===H)O++;else T++;else if(M===H)T++;else O++}B.innerHTML="",B.style.display="block",B.appendChild(q("div",{className:"h2h-record"},q("span",{className:"h2h-model"},H),q("span",{className:"h2h-wins"},` ${O}W`),q("span",{className:"muted"}," / "),q("span",{className:"h2h-losses"},`${T}L`),q("span",{className:"muted"}," / "),q("span",{className:"h2h-ties"},`${C}T`),q("span",{className:"muted"}," vs "),q("span",{className:"h2h-model"},F)))}else B.style.display="none";v.innerHTML="";let j=Math.max(1,Math.ceil(Z.length/w));if(R>=j)R=j-1;let s=R*w,Vq=Z.slice(s,s+w);function n(){let O=q("div",{className:"pagination"}),T=q("button",{disabled:R===0,onClick:()=>{R--,P()}},"< prev"),C=q("button",{disabled:R>=j-1,onClick:()=>{R++,P()}},"next >");O.appendChild(T),O.appendChild(q("span",{className:"muted"},` page ${R+1} of ${j} `)),O.appendChild(C);let k=document.createElement("select");k.className="page-size-select";for(let M of[10,25,50,100]){let g=new Option(`${M} per page`,String(M));if(M===w)g.selected=!0;k.appendChild(g)}return k.addEventListener("change",()=>{w=Number(k.value),R=0,P()}),O.appendChild(k),O}let a=Z.length>10;if(a)v.appendChild(n());else v.appendChild(q("p",{className:"muted small mb-1"},`${Z.length} judgments`));for(let O of Vq){let T=K.config.prompts.find((c)=>c.id===O.promptId),{labelA:C,labelB:k,winnerLabel:M}=Rq(O,X),g=O.winner==="A"?"a":O.winner==="B"?"b":"tie",Wq=q("a",{href:"#",className:"judgment-sample-link",onClick:(c)=>{c.preventDefault(),l(O.sampleA,K)}},C),Xq=q("a",{href:"#",className:"judgment-sample-link",onClick:(c)=>{c.preventDefault(),l(O.sampleB,K)}},k),f=q("div",{className:"judgment"});if(f.appendChild(q("div",{className:"judgment-header"},q("span",{className:"judgment-stage"},O.stage),q("span",{},` ${T?.name??O.promptId}`),q("span",{className:"judgment-judge"},`Judge: ${O.judgeModel}`))),f.appendChild(q("div",{className:"judgment-matchup"},Wq,q("span",{className:"muted"}," vs "),Xq)),f.appendChild(q("div",{className:"judgment-result"},q("span",{className:"muted"},"→ "),q("span",{className:`judgment-winner ${g}`},M))),O.reasoning)f.appendChild(q("div",{className:"judgment-reasoning"},O.reasoning));v.appendChild(f)}if(a)v.appendChild(n())};return y.addEventListener("change",()=>{z=y.value,_=null,R=0,P()}),I.addEventListener("change",()=>{Y=I.value,_=null,R=0,P()}),L.addEventListener("change",()=>{V=L.value,_=null,R=0,P()}),E.addEventListener("change",()=>{H=E.value,_=null,R=0,P()}),A.addEventListener("change",()=>{F=A.value,_=null,R=0,P()}),m={focusSample(Z){let j=X.get(Z);_=Z,z="all",Y="all",V="all",H=j?.model??"all",F="all",y.value="all",I.value="all",L.value="all",E.value=H,A.value="all",P(),Q.scrollIntoView({behavior:"smooth"})},focusModel(Z){_=null,z="all",H=Z,F="all",Y="all",V="all",y.value="all",I.value="all",L.value="all",E.value=Z,A.value="all",P(),Q.scrollIntoView({behavior:"smooth"})}},P(),Q}function Dq(K){let Q=q("div"),W=q("div",{className:"cost-grid"}),X=K.meta.totalCostUncached??K.meta.totalCost;if(W.appendChild(o("Total Cost",`$${X.toFixed(4)}`)),W.appendChild(o("Duration",`${(K.meta.durationMs/1000).toFixed(1)}s`)),W.appendChild(o("Total Tokens",K.meta.totalTokens.toLocaleString())),Q.appendChild(W),K.modelInfo&&Object.keys(K.modelInfo).length>0){Q.appendChild(q("h3",{},"Models"));let U=q("div",{className:"model-cards"});for(let[N,G]of Object.entries(K.modelInfo))U.appendChild(q("div",{className:"model-card"},q("div",{className:"name"},N),q("div",{className:"detail"},G.name),q("div",{className:"detail"},`Family: ${G.family}`),q("div",{className:"detail"},`$${G.costPer1MInput}/M in, $${G.costPer1MOutput}/M out`),G.releaseDate?q("div",{className:"detail"},`Released: ${G.releaseDate}`):null,q("div",{className:"detail"},G.openWeights?"Open weights":"Proprietary")));Q.appendChild(U)}return Q}function Eq(){let K=q("div",{className:"methodology"},q("h2",{},"How Models Are Compared"),q("p",{},'Writing quality is evaluated through pairwise blind judging. For each prompt, an LLM judge is shown two writing samples labeled "Sample A" and "Sample B" with no indication of which model produced which text. The judge decides which sample is better (A, B, or tie) and provides reasoning.'),q("p",{},"Each prompt defines its own judging criteria tailored to the genre. A sermon prompt might specify theological accuracy and pastoral warmth, while a short story prompt might focus on narrative voice and character interiority. The judge evaluates against all listed criteria holistically."),q("p",{},"Judging uses structured JSON output (a Zod schema requesting winner and reasoning). If a judge model does not support structured output, the system falls back to free-text generation and extracts JSON from the response."),q("h3",{},"Position Bias Mitigation"),q("p",{},"LLMs can exhibit position bias — a tendency to favor whichever sample "+"appears first. To counteract this, the benchmark randomly swaps the presentation order of each pair with 50% probability. After the judge responds, the winner is mapped back to the canonical ordering. This ensures that any position preference cancels out over many comparisons."),q("h2",{},"The Benchmark Pipeline"),q("p",{},"The benchmark uses a pull-based adaptive architecture. Instead of "+"generating all pairwise judgments upfront (O(n²) model pairs), "+"the system uses confidence intervals to decide what work to do next, stopping as soon as ratings are sufficiently precise."),q("h3",{},"Phase 1: Cache Seeding"),q("p",{},"Before making any API calls, the runner exhaustively scans the disk cache and loads all previously computed artifacts: writing samples, feedback, revisions, and judgments. This populates the rating model at zero cost and ensures no redundant work is repeated."),q("h3",{},"Phase 2: Adaptive Pull Loop"),q("p",{},"The system iterates: compute Whole History Rating with confidence "+"intervals → identify the model pair and judgment type whose data "+"would most reduce uncertainty → generate only that work → repeat "+"until all CIs are below a configurable threshold (default ±100 Elo points)."),q("p",{},"When a judgment is needed, the system cascades through dependencies automatically. For example, requesting an improvement judgment triggers writing the initial sample, generating feedback, and producing the revision if any of those are missing. This ensure-cascade pattern means the system only creates artifacts that are actually needed to reduce rating uncertainty."),q("h3",{},"Judgment Types"),q("ol",{},q("li",{},q("strong",{},"Initial")," — Pairwise blind comparison of initial writing outputs. "+"Measures raw writing quality."),q("li",{},q("strong",{},"Improvement")," — Each revision is compared against its own original to "+"measure whether the feedback actually helped. This determines feedback quality ratings."),q("li",{},q("strong",{},"Revised")," — Revised outputs are compared head-to-head, scoped by "+"feedback source. Measures revised writing quality.")),q("h3",{},"Information-Gain Scoring"),q("p",{},"The need identifier scores candidate judgments by expected "+"information gain: score = (σ²_A + σ²_B) × p × (1−p), where "+"σ is each model’s CI half-width and p is the predicted win "+"probability. Pairs with high uncertainty and close predicted strength score highest. Improvement and revised judgments receive cascade cost discounts (0.25 and 0.2 respectively) since they require additional prerequisite API calls."),q("h2",{},"Whole History Rating System"),q("p",{},"Within each run, ratings are computed using Whole History Rating (WHR), a Bayesian extension of the Bradley-Terry model. WHR uses "+"Newton’s method to find the maximum a posteriori (MAP) estimate "+"of model strengths, producing both point estimates and confidence "+"intervals. These CIs drive the adaptive loop’s stopping criterion."),q("h3",{},"The Algorithm"),q("p",{},"Each model is assigned a log-strength parameter r (initially 0). The algorithm maximizes the log-posterior:"),q("div",{className:"formula"},`log P(r | data) = Σ [winsᵢⱼ · log σ(rᵢ − rⱼ) + winsⱼᵢ · log σ(rⱼ − rᵢ)]
`+`                 − Σ rᵢ² / (2σ²)    (Gaussian prior, σ² = 0.25)

`+`Newton update: (−H) · Δ = g,  r ← r + Δ
`+`Repeat until convergence (max |Δ| < 10⁻⁶, up to 50 iterations).
`+"Center ratings by subtracting the mean."),q("p",{},"The Gaussian prior (σ² = 0.25) regularizes the optimization, "+"preventing divergence when a model wins or loses all games. This replaces the geometric-mean normalization used in standard Bradley-Terry and ensures symmetric, well-defined confidence intervals."),q("h3",{},"Confidence Intervals"),q("p",{},"95% confidence intervals are derived from the diagonal of the inverse Hessian (the observed Fisher information). The CI "+"half-width for model i is 1.96 × √([−H]⁻¹ᵢᵢ), converted to "+"Elo scale. Wider CIs indicate less certainty; the adaptive loop targets the model pair that would most efficiently reduce the largest CI."),q("h3",{},"ELO-Scale Conversion"),q("p",{},"Log-strengths are converted to a familiar ELO-like scale:"),q("div",{className:"formula"},"rating = round(r × 400 / ln(10) + 1500)"),q("p",{},"A 400-point gap corresponds to roughly 10:1 expected win odds. The baseline is 1500."),q("h2",{},"Three Rating Dimensions"),q("p",{},"The adaptive loop tracks three independent rating dimensions, each of which must converge before the run completes:"),q("h3",{},"Writing ELO"),q("p",{},"Direct head-to-head writing quality from initial stage judgments. Two writing samples for the same prompt are shown to a judge; the winning model gets credit."),q("h3",{},"Feedback ELO"),q("p",{},"How useful a model’s editorial feedback is, measured indirectly. "+"The system does not compare feedback texts directly. Instead, it uses improvement judgments (revision vs. original) to determine whether feedback led to a better revision."),q("p",{},"The algorithm groups improvement judgments by prompt and judge, then pairs up different feedback providers within each group. If "+"feedback model A’s revision beat the original but feedback model "+"B’s did not, A wins. If both improved or both failed, it’s a tie. "+"These synthetic pairwise outcomes are then fed into the same WHR computation."),q("h3",{},"Revised Writing ELO"),q("p",{},"Revised outputs are compared head-to-head, scoped by feedback source so the comparison isolates writing ability from feedback quality. This uses the same WHR computation as initial writing."),q("h3",{},"Per-Tag ELO"),q("p",{},'Each prompt has genre tags (e.g. "speech", "theological", "creative"). Per-tag ratings run the same Bradley-Terry computation restricted to judgments from prompts with a given tag. This reveals '+"category-specific strengths — a model might excel at essays but "+"struggle with creative fiction."),q("h2",{},"Cumulative Ratings"),q("p",{},"Ratings accumulate across multiple benchmark runs. The cumulative system uses standard Bradley-Terry (not WHR), storing pairwise records: for each pair of models, the total number of wins for each side and ties."),q("p",{},"When a new run completes, its pairwise outcomes are merged with the existing accumulated records. Ratings are then recomputed from scratch using Bradley-Terry on the full merged dataset. This means the order in which runs are processed does not affect the final ratings."),q("p",{},"The leaderboard on the dashboard page always reflects the cumulative ratings across all runs. Individual run pages show "+"WHR ratings with confidence intervals computed from that run’s "+"judgments alone."),q("h2",{},"Reading the Results"),q("ul",{},q("li",{},q("strong",{},"1500")," is the baseline rating. A model at the mean of all model strengths sits at 1500."),q("li",{},q("strong",{},"400-point gap")," corresponds to roughly 10:1 expected win odds. A model rated 1900 is expected to beat a 1500-rated model about 90% of the time."),q("li",{},q("strong",{},"±CI")," is the 95% confidence interval half-width in Elo points, derived from the Hessian of the WHR log-posterior. Smaller values indicate more precise ratings."),q("li",{},q("strong",{},"W / L / T")," are raw win, loss, and tie counts from all pairwise matches the model participated in."),q("li",{},q("strong",{},"Matches")," is the total number of pairwise comparisons involving the model (W + L + T). More matches produce more reliable ratings.")),q("p",{className:"note"},"The adaptive runner stops collecting judgments once all model CIs "+"are below the configured threshold (default ±100 Elo points). "+"Use --confidence to adjust this target."));b(K.outerHTML)}async function Lq(){h(".nav a[data-page]").forEach((K)=>{K.addEventListener("click",(Q)=>{Q.preventDefault(),history.pushState(null,"",K.getAttribute("href")),d()})}),window.addEventListener("popstate",d);try{i.index=await Yq()}catch(K){if(qq().page!=="methodology"){Kq(K instanceof Error?K.message:String(K));return}}d()}function d(){let{page:K,id:Q}=qq();switch(m=null,h(".nav a").forEach((W)=>{let X=W.getAttribute("data-page"),U=X===K||K==="run"&&X==="runs";W.classList.toggle("active",U)}),K){case"dashboard":Hq(i.index);break;case"runs":Fq(i.index);break;case"run":Tq(Q);break;case"methodology":Eq();break}}async function Tq(K){b('<div id="loading">loading run...</div>');try{let Q=await Zq(K);Oq(Q)}catch(Q){Kq(Q instanceof Error?Q.message:String(Q))}}Lq();
